{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvue — Complete Feature Guide\n",
    "\n",
    "**Eigenvue** is a visual learning platform for understanding algorithms, AI architectures, and quantum computing. It provides interactive, step-by-step visualizations that help learners build intuition for complex computational concepts.\n",
    "\n",
    "This notebook demonstrates **every feature** the `eigenvue` Python package offers, organized into the following sections:\n",
    "\n",
    "| # | Section | What You'll Learn |\n",
    "|---|---------|-------------------|\n",
    "| 1 | [Installation](#1.-Installation) | How to install `eigenvue` from PyPI |\n",
    "| 2 | [Quick Start](#2.-Quick-Start) | Import the library and check the version |\n",
    "| 3 | [`eigenvue.list()`](#3.-Discovering-Algorithms-with-eigenvue.list()) | Browse all 17 algorithms and filter by category |\n",
    "| 4 | [`eigenvue.steps()`](#4.-Programmatic-Step-Inspection-with-eigenvue.steps()) | Generate and inspect algorithm execution traces |\n",
    "| 5 | [`eigenvue.show()`](#5.-Interactive-Browser-Visualization-with-eigenvue.show()) | Launch visualizations in the browser |\n",
    "| 6 | [`eigenvue.jupyter()`](#6.-Jupyter-Notebook-Integration-with-eigenvue.jupyter()) | Embed visualizations directly in notebook cells |\n",
    "| 7 | [Classical Algorithms](#7.-Classical-Algorithms) | Binary Search, Bubble Sort, QuickSort, Merge Sort, BFS, DFS, Dijkstra |\n",
    "| 8 | [Deep Learning Algorithms](#8.-Deep-Learning-Algorithms) | Perceptron, Feedforward Network, Backpropagation, Convolution, Gradient Descent |\n",
    "| 9 | [Generative AI / Transformers](#9.-Generative-AI-/-Transformers) | BPE Tokenization, Token Embeddings, Self-Attention, Multi-Head Attention, Transformer Block |\n",
    "| 10 | [Custom Inputs](#10.-Custom-Inputs) | Override default parameters for any algorithm |\n",
    "| 11 | [Step Data Deep Dive](#11.-Step-Data-Deep-Dive) | Understand the full step schema (state, visual actions, code highlights) |\n",
    "| 12 | [Error Handling](#12.-Error-Handling) | How the library handles invalid inputs gracefully |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Installation\n",
    "\n",
    "Eigenvue is distributed on [PyPI](https://pypi.org/project/eigenvue/). Install it with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eigenvue in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: flask<4.0,>=3.0 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from eigenvue) (3.1.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue) (8.3.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue) (3.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=8.1.3->flask<4.0,>=3.0->eigenvue) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Standard installation\n",
    "!pip install eigenvue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eigenvue[jupyter] in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: flask<4.0,>=3.0 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from eigenvue[jupyter]) (3.1.2)\n",
      "Requirement already satisfied: ipython>=8.0 in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from eigenvue[jupyter]) (8.37.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue[jupyter]) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue[jupyter]) (8.3.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue[jupyter]) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue[jupyter]) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue[jupyter]) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask<4.0,>=3.0->eigenvue[jupyter]) (3.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=8.1.3->flask<4.0,>=3.0->eigenvue[jupyter]) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (1.3.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=8.0->eigenvue[jupyter]) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=8.0->eigenvue[jupyter]) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=8.0->eigenvue[jupyter]) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=8.0->eigenvue[jupyter]) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=8.0->eigenvue[jupyter]) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ashut\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=8.0->eigenvue[jupyter]) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\ashut\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# For Jupyter notebook integration (includes IPython dependency)\n",
    "!pip install eigenvue[jupyter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements:**\n",
    "- Python 3.10+\n",
    "- Flask 3.0+ (installed automatically)\n",
    "- IPython 8.0+ (only needed for `eigenvue.jupyter()`, installed with `eigenvue[jupyter]`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvue version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import eigenvue\n",
    "\n",
    "print(f\"Eigenvue version: {eigenvue.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library exposes exactly **four public functions** — each designed for a different workflow:\n",
    "\n",
    "| Function | Purpose |\n",
    "|----------|--------|\n",
    "| `eigenvue.list()` | Discover available algorithms and their metadata |\n",
    "| `eigenvue.steps()` | Generate step-by-step execution traces programmatically |\n",
    "| `eigenvue.show()` | Launch an interactive visualization in the browser |\n",
    "| `eigenvue.jupyter()` | Embed an interactive visualization in a Jupyter cell |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Discovering Algorithms with `eigenvue.list()`\n",
    "\n",
    "`eigenvue.list()` returns a list of `AlgorithmInfo` objects describing every available algorithm. Each object exposes:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| `id` | `str` | URL-safe identifier (e.g., `\"binary-search\"`) |\n",
    "| `name` | `str` | Human-readable name (e.g., `\"Binary Search\"`) |\n",
    "| `category` | `str` | One of: `\"classical\"`, `\"deep-learning\"`, `\"generative-ai\"` |\n",
    "| `description` | `str` | Short summary (≤80 characters) |\n",
    "| `difficulty` | `str` | One of: `\"beginner\"`, `\"intermediate\"`, `\"advanced\"`, `\"expert\"` |\n",
    "| `time_complexity` | `str` | Big-O time complexity |\n",
    "| `space_complexity` | `str` | Big-O space complexity |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 List All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total algorithms available: 17\n",
      "\n",
      "  binary-search             Binary Search                       [classical]\n",
      "  bfs                       Breadth-First Search                [classical]\n",
      "  bubble-sort               Bubble Sort                         [classical]\n",
      "  dfs                       Depth-First Search                  [classical]\n",
      "  dijkstra                  Dijkstra's Shortest Path            [classical]\n",
      "  merge-sort                Merge Sort                          [classical]\n",
      "  quicksort                 QuickSort                           [classical]\n",
      "  backpropagation           Backpropagation                     [deep-learning]\n",
      "  convolution               Convolution (2D)                    [deep-learning]\n",
      "  feedforward-network       Feedforward Neural Network          [deep-learning]\n",
      "  gradient-descent          Gradient Descent                    [deep-learning]\n",
      "  perceptron                Perceptron                          [deep-learning]\n",
      "  tokenization-bpe          BPE Tokenization                    [generative-ai]\n",
      "  multi-head-attention      Multi-Head Attention                [generative-ai]\n",
      "  self-attention            Self-Attention (Scaled Dot-Product) [generative-ai]\n",
      "  token-embeddings          Token Embeddings                    [generative-ai]\n",
      "  transformer-block         Transformer Block                   [generative-ai]\n"
     ]
    }
   ],
   "source": [
    "all_algorithms = eigenvue.list()\n",
    "\n",
    "print(f\"Total algorithms available: {len(all_algorithms)}\\n\")\n",
    "\n",
    "for algo in all_algorithms:\n",
    "    print(f\"  {algo.id:<25s} {algo.name:<35s} [{algo.category}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Inspect a Single Algorithm's Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:               binary-search\n",
      "Name:             Binary Search\n",
      "Category:         classical\n",
      "Description:      Efficiently find a target in a sorted array by halving the search space.\n",
      "Difficulty:       beginner\n",
      "Time Complexity:  O(log n)\n",
      "Space Complexity: O(1)\n"
     ]
    }
   ],
   "source": [
    "algo = all_algorithms[0]\n",
    "\n",
    "print(f\"ID:               {algo.id}\")\n",
    "print(f\"Name:             {algo.name}\")\n",
    "print(f\"Category:         {algo.category}\")\n",
    "print(f\"Description:      {algo.description}\")\n",
    "print(f\"Difficulty:       {algo.difficulty}\")\n",
    "print(f\"Time Complexity:  {algo.time_complexity}\")\n",
    "print(f\"Space Complexity: {algo.space_complexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Filter by Category\n",
    "\n",
    "Pass the `category` parameter to filter algorithms. Valid categories:\n",
    "- `\"classical\"` — Sorting, searching, and graph algorithms\n",
    "- `\"deep-learning\"` — Neural network fundamentals\n",
    "- `\"generative-ai\"` — Transformer and language model building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical algorithms (7):\n",
      "  Binary Search                   beginner         O(log n)\n",
      "  Breadth-First Search            intermediate     O(V + E)\n",
      "  Bubble Sort                     beginner         O(n²)\n",
      "  Depth-First Search              intermediate     O(V + E)\n",
      "  Dijkstra's Shortest Path        advanced         O((V + E) log V)\n",
      "  Merge Sort                      intermediate     O(n log n)\n",
      "  QuickSort                       intermediate     O(n log n)\n"
     ]
    }
   ],
   "source": [
    "classical = eigenvue.list(category=\"classical\")\n",
    "print(f\"Classical algorithms ({len(classical)}):\")\n",
    "for algo in classical:\n",
    "    print(f\"  {algo.name:<30s}  {algo.difficulty:<15s}  {algo.time_complexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning algorithms (5):\n",
      "  Backpropagation                 intermediate     O(Σ n_l × n_{l+1})\n",
      "  Convolution (2D)                intermediate     O(H × W × K² × C)\n",
      "  Feedforward Neural Network      intermediate     O(Σ n_l × n_{l+1})\n",
      "  Gradient Descent                intermediate     O(T × d)\n",
      "  Perceptron                      beginner         O(n × d)\n"
     ]
    }
   ],
   "source": [
    "deep_learning = eigenvue.list(category=\"deep-learning\")\n",
    "print(f\"Deep Learning algorithms ({len(deep_learning)}):\")\n",
    "for algo in deep_learning:\n",
    "    print(f\"  {algo.name:<30s}  {algo.difficulty:<15s}  {algo.time_complexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI algorithms (5):\n",
      "  BPE Tokenization                          beginner         O(n × m)\n",
      "  Multi-Head Attention                      advanced         O(h × n² × d_k)\n",
      "  Self-Attention (Scaled Dot-Product)       intermediate     O(n² × d)\n",
      "  Token Embeddings                          intermediate     O(n × d)\n",
      "  Transformer Block                         advanced         O(n² × d + n × d × d_ff)\n"
     ]
    }
   ],
   "source": [
    "gen_ai = eigenvue.list(category=\"generative-ai\")\n",
    "print(f\"Generative AI algorithms ({len(gen_ai)}):\")\n",
    "for algo in gen_ai:\n",
    "    print(f\"  {algo.name:<40s}  {algo.difficulty:<15s}  {algo.time_complexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Summary Table of All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                        Name                                     Category         Difficulty      Time                 Space\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "binary-search             Binary Search                            classical        beginner        O(log n)             O(1)\n",
      "bfs                       Breadth-First Search                     classical        intermediate    O(V + E)             O(V)\n",
      "bubble-sort               Bubble Sort                              classical        beginner        O(n²)                O(1)\n",
      "dfs                       Depth-First Search                       classical        intermediate    O(V + E)             O(V)\n",
      "dijkstra                  Dijkstra's Shortest Path                 classical        advanced        O((V + E) log V)     O(V)\n",
      "merge-sort                Merge Sort                               classical        intermediate    O(n log n)           O(n)\n",
      "quicksort                 QuickSort                                classical        intermediate    O(n log n)           O(log n)\n",
      "backpropagation           Backpropagation                          deep-learning    intermediate    O(Σ n_l × n_{l+1})   O(Σ n_l × n_{l+1})\n",
      "convolution               Convolution (2D)                         deep-learning    intermediate    O(H × W × K² × C)    O(H × W + K²)\n",
      "feedforward-network       Feedforward Neural Network               deep-learning    intermediate    O(Σ n_l × n_{l+1})   O(Σ n_l × n_{l+1})\n",
      "gradient-descent          Gradient Descent                         deep-learning    intermediate    O(T × d)             O(d)\n",
      "perceptron                Perceptron                               deep-learning    beginner        O(n × d)             O(d)\n",
      "tokenization-bpe          BPE Tokenization                         generative-ai    beginner        O(n × m)             O(n)\n",
      "multi-head-attention      Multi-Head Attention                     generative-ai    advanced        O(h × n² × d_k)      O(h × n² + n × d)\n",
      "self-attention            Self-Attention (Scaled Dot-Product)      generative-ai    intermediate    O(n² × d)            O(n² + n × d)\n",
      "token-embeddings          Token Embeddings                         generative-ai    intermediate    O(n × d)             O(V × d)\n",
      "transformer-block         Transformer Block                        generative-ai    advanced        O(n² × d + n × d × d_ff) O(n² + n × d_ff)\n"
     ]
    }
   ],
   "source": [
    "# Build a formatted summary table\n",
    "header = f\"{'ID':<25s} {'Name':<40s} {'Category':<16s} {'Difficulty':<15s} {'Time':<20s} {'Space'}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for algo in eigenvue.list():\n",
    "    print(\n",
    "        f\"{algo.id:<25s} {algo.name:<40s} {algo.category:<16s} \"\n",
    "        f\"{algo.difficulty:<15s} {algo.time_complexity:<20s} {algo.space_complexity}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Programmatic Step Inspection with `eigenvue.steps()`\n",
    "\n",
    "`eigenvue.steps()` generates the complete execution trace for any algorithm and returns it as a list of Python dictionaries. This is useful for:\n",
    "\n",
    "- **Programmatic inspection** — Examine how an algorithm processes data step by step\n",
    "- **Testing and verification** — Validate algorithm behavior against expected outputs\n",
    "- **Data export** — Convert steps to JSON for external tools or custom visualizations\n",
    "\n",
    "**Signature:**\n",
    "```python\n",
    "eigenvue.steps(\n",
    "    algorithm_id: str,\n",
    "    inputs: dict | None = None,   # None → uses algorithm defaults\n",
    ") -> list[dict]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Generate Steps with Default Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: Binary Search\n",
      "Total steps: 9\n",
      "First step terminal? False\n",
      "Last step terminal?  True\n",
      "\n",
      "  Step  0: Initialize Search\n",
      "  Step  1: Calculate Middle (Iteration 1)\n",
      "  Step  2: Search Right Half\n",
      "  Step  3: Calculate Middle (Iteration 2)\n",
      "  Step  4: Search Left Half\n",
      "  Step  5: Calculate Middle (Iteration 3)\n",
      "  Step  6: Search Right Half\n",
      "  Step  7: Calculate Middle (Iteration 4)\n",
      "  Step  8: Target Found! [FINAL]\n"
     ]
    }
   ],
   "source": [
    "steps = eigenvue.steps(\"binary-search\")\n",
    "\n",
    "print(f\"Algorithm: Binary Search\")\n",
    "print(f\"Total steps: {len(steps)}\")\n",
    "print(f\"First step terminal? {steps[0]['isTerminal']}\")\n",
    "print(f\"Last step terminal?  {steps[-1]['isTerminal']}\")\n",
    "print()\n",
    "\n",
    "for step in steps:\n",
    "    terminal_marker = \" [FINAL]\" if step[\"isTerminal\"] else \"\"\n",
    "    print(f\"  Step {step['index']:>2d}: {step['title']}{terminal_marker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Generate Steps with Custom Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 10 in [2, 4, 6, 8, 10, 12, 14]\n",
      "Total steps: 7\n",
      "\n",
      "  Step 0: Initialize Search\n",
      "    → Searching for 10 in a sorted array of 7 elements. Setting left = 0, right = 6. The entire array is t...\n",
      "  Step 1: Calculate Middle (Iteration 1)\n",
      "    → mid = floor((0 + 6) / 2) = floor(6 / 2) = 3. Checking array[3] = 8.\n",
      "  Step 2: Search Right Half\n",
      "    → array[3] = 8 < target 10. Target must be in the right half. Setting left = 3 + 1 = 4.\n",
      "  Step 3: Calculate Middle (Iteration 2)\n",
      "    → mid = floor((4 + 6) / 2) = floor(10 / 2) = 5. Checking array[5] = 12.\n",
      "  Step 4: Search Left Half\n",
      "    → array[5] = 12 > target 10. Target must be in the left half. Setting right = 5 - 1 = 4.\n",
      "  Step 5: Calculate Middle (Iteration 3)\n",
      "    → mid = floor((4 + 4) / 2) = floor(8 / 2) = 4. Checking array[4] = 10.\n",
      "  Step 6: Target Found!\n",
      "    → array[4] = 10 equals target 10. Found at index 4 after 3 iterations.\n"
     ]
    }
   ],
   "source": [
    "steps = eigenvue.steps(\n",
    "    \"binary-search\",\n",
    "    inputs={\"array\": [2, 4, 6, 8, 10, 12, 14], \"target\": 10}\n",
    ")\n",
    "\n",
    "print(f\"Searching for 10 in [2, 4, 6, 8, 10, 12, 14]\")\n",
    "print(f\"Total steps: {len(steps)}\\n\")\n",
    "\n",
    "for step in steps:\n",
    "    print(f\"  Step {step['index']}: {step['title']}\")\n",
    "    print(f\"    → {step['explanation'][:100]}...\" if len(step['explanation']) > 100 else f\"    → {step['explanation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Examining Step Details\n",
    "\n",
    "Each step dictionary contains rich metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in a step dictionary:\n",
      "  index              → 2\n",
      "  id                 → search_right\n",
      "  title              → Search Right Half\n",
      "  explanation        → array[4] = 9 < target 13. Target must be in the right half. Setting left = 4 + 1...\n",
      "  state              → {'array': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19], 'target': 13, 'left': 5, 'right':...\n",
      "  visualActions      → [{'type': 'dimRange', 'from': 0, 'to': 4}, {'type': 'highlightRange', 'from': 5,...\n",
      "  codeHighlight      → {'language': 'pseudocode', 'lines': [10, 11]}\n",
      "  isTerminal         → False\n",
      "  phase              → search\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "steps = eigenvue.steps(\"binary-search\")\n",
    "step = steps[2]  # Pick a mid-execution step\n",
    "\n",
    "print(\"Keys in a step dictionary:\")\n",
    "for key in step.keys():\n",
    "    value_preview = str(step[key])[:80]\n",
    "    print(f\"  {key:<18s} → {value_preview}{'...' if len(str(step[key])) > 80 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"index\": 2,\n",
      "  \"id\": \"search_right\",\n",
      "  \"title\": \"Search Right Half\",\n",
      "  \"explanation\": \"array[4] = 9 < target 13. Target must be in the right half. Setting left = 4 + 1 = 5.\",\n",
      "  \"state\": {\n",
      "    \"array\": [\n",
      "      1,\n",
      "      3,\n",
      "      5,\n",
      "      7,\n",
      "      9,\n",
      "      11,\n",
      "      13,\n",
      "      15,\n",
      "      17,\n",
      "      19\n",
      "    ],\n",
      "    \"target\": 13,\n",
      "    \"left\": 5,\n",
      "    \"right\": 9,\n",
      "    \"mid\": 4,\n",
      "    \"result\": null\n",
      "  },\n",
      "  \"visualActions\": [\n",
      "    {\n",
      "      \"type\": \"dimRange\",\n",
      "      \"from\": 0,\n",
      "      \"to\": 4\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"highlightRange\",\n",
      "      \"from\": 5,\n",
      "      \"to\": 9,\n",
      "      \"color\": \"highlight\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"movePointer\",\n",
      "      \"id\": \"left\",\n",
      "      \"to\": 5\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"movePointer\",\n",
      "      \"id\": \"right\",\n",
      "      \"to\": 9\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"movePointer\",\n",
      "      \"id\": \"mid\",\n",
      "      \"to\": 4\n",
      "    }\n",
      "  ],\n",
      "  \"codeHighlight\": {\n",
      "    \"language\": \"pseudocode\",\n",
      "    \"lines\": [\n",
      "      10,\n",
      "      11\n",
      "    ]\n",
      "  },\n",
      "  \"isTerminal\": false,\n",
      "  \"phase\": \"search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Detailed view of a single step\n",
    "print(json.dumps(step, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Interactive Browser Visualization with `eigenvue.show()`\n",
    "\n",
    "`eigenvue.show()` launches a lightweight local server and opens an interactive visualization in your default web browser.\n",
    "\n",
    "**Signature:**\n",
    "```python\n",
    "eigenvue.show(\n",
    "    algorithm_id: str,\n",
    "    inputs: dict | None = None,     # None → uses algorithm defaults\n",
    "    *,\n",
    "    port: int = 0,                  # 0 → auto-select an available port\n",
    "    open_browser: bool = True,      # Automatically open the browser\n",
    ")\n",
    "```\n",
    "\n",
    "**Key behaviors:**\n",
    "- Runs entirely on **localhost** — no internet connection required\n",
    "- Server **blocks** until you press `Ctrl+C` in the terminal\n",
    "- Auto-selects a free port when `port=0` (the default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment any line below to launch a browser visualization.\n",
    "# The cell will block until you press Ctrl+C (or interrupt the kernel).\n",
    "\n",
    "# eigenvue.show(\"binary-search\")\n",
    "# eigenvue.show(\"self-attention\", inputs={\"tokens\": [\"You\", \"love\", \"AI\"], \"embeddingDim\": 4})\n",
    "# eigenvue.show(\"dijkstra\", port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Jupyter Notebook Integration with `eigenvue.jupyter()`\n",
    "\n",
    "`eigenvue.jupyter()` embeds an interactive visualization directly inside a notebook cell using an IFrame. Works in JupyterLab, Jupyter Notebook, and Google Colab.\n",
    "\n",
    "**Signature:**\n",
    "```python\n",
    "eigenvue.jupyter(\n",
    "    algorithm_id: str,\n",
    "    inputs: dict | None = None,     # None → uses algorithm defaults\n",
    "    *,\n",
    "    width: str = \"100%\",            # CSS width for the IFrame\n",
    "    height: str = \"600px\",          # CSS height for the IFrame\n",
    ") -> IPython.display.IFrame\n",
    "```\n",
    "\n",
    "> **Note:** Requires IPython. Install with `pip install eigenvue[jupyter]` if not already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'eigenvue.server'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:53886\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"http://127.0.0.1:53886\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2209c94a260>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed a Self-Attention visualization directly in this cell\n",
    "eigenvue.jupyter(\"self-attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'eigenvue.server'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:53889\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"http://127.0.0.1:53889\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2209c94b4f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customize the display dimensions\n",
    "eigenvue.jupyter(\"binary-search\", width=\"100%\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Classical Algorithms\n",
    "\n",
    "Eigenvue includes **7 classical algorithms** covering searching, sorting, and graph traversal — the foundations of computer science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Binary Search\n",
    "\n",
    "Efficiently find a target in a sorted array by halving the search space.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `binary-search` |\n",
    "| **Difficulty** | Beginner |\n",
    "| **Time** | O(log n) |\n",
    "| **Space** | O(1) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Search — 9 steps to find target\n",
      "\n",
      "  Step 0: Initialize Search\n",
      "  Step 1: left=0, mid=4, right=9 — Calculate Middle (Iteration 1)\n",
      "  Step 2: left=5, mid=4, right=9 — Search Right Half\n",
      "  Step 3: left=5, mid=7, right=9 — Calculate Middle (Iteration 2)\n",
      "  Step 4: left=5, mid=7, right=6 — Search Left Half\n",
      "  Step 5: left=5, mid=5, right=6 — Calculate Middle (Iteration 3)\n",
      "  Step 6: left=6, mid=5, right=6 — Search Right Half\n",
      "  Step 7: left=6, mid=6, right=6 — Calculate Middle (Iteration 4)\n",
      "  Step 8: left=6, mid=6, right=6 — Target Found!\n"
     ]
    }
   ],
   "source": [
    "# Default: search for 13 in [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "steps = eigenvue.steps(\"binary-search\")\n",
    "print(f\"Binary Search — {len(steps)} steps to find target\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    state = s[\"state\"]\n",
    "    if \"left\" in state and \"right\" in state and \"mid\" in state:\n",
    "        print(f\"  Step {s['index']}: left={state['left']}, mid={state['mid']}, right={state['right']} — {s['title']}\")\n",
    "    else:\n",
    "        print(f\"  Step {s['index']}: {s['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Bubble Sort\n",
    "\n",
    "Repeatedly swap adjacent out-of-order elements until the array is sorted.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `bubble-sort` |\n",
    "| **Difficulty** | Beginner |\n",
    "| **Time** | O(n²) |\n",
    "| **Space** | O(1) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bubble Sort — 43 steps\n",
      "\n",
      "  First step: Initialize Bubble Sort\n",
      "  Last step:  No Swaps — Early Termination\n",
      "\n",
      "  Initial array: [64, 34, 25, 12, 22, 11, 90]\n",
      "  Final array:   [11, 12, 22, 25, 34, 64, 90]\n"
     ]
    }
   ],
   "source": [
    "# Default: sort [64, 34, 25, 12, 22, 11, 90]\n",
    "steps = eigenvue.steps(\"bubble-sort\")\n",
    "print(f\"Bubble Sort — {len(steps)} steps\\n\")\n",
    "print(f\"  First step: {steps[0]['title']}\")\n",
    "print(f\"  Last step:  {steps[-1]['title']}\")\n",
    "\n",
    "# Show the initial and final array state\n",
    "print(f\"\\n  Initial array: {steps[0]['state'].get('array', 'N/A')}\")\n",
    "print(f\"  Final array:   {steps[-1]['state'].get('array', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 QuickSort\n",
    "\n",
    "Divide-and-conquer sort using pivot partitioning.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `quicksort` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(n log n) average |\n",
    "| **Space** | O(log n) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuickSort — 23 steps\n",
      "\n",
      "  Step  0: Initialize QuickSort\n",
      "  Step  1: Select Pivot = 10\n",
      "  Step  2: Compare [0] with Pivot\n",
      "  Step  3: Compare [1] with Pivot\n",
      "  Step  4: Compare [2] with Pivot\n",
      "  Step  5: Compare [3] with Pivot\n",
      "  Step  6: Swap [0] ↔ [3]\n",
      "  Step  7: Compare [4] with Pivot\n",
      "  Step  8: Swap [1] ↔ [4]\n",
      "  Step  9: Compare [5] with Pivot\n",
      "  Step 10: Pivot Placed at [2]\n",
      "  Step 11: Select Pivot = 9\n",
      "  Step 12: Compare [0] with Pivot\n",
      "  Step 13: Pivot Placed at [1]\n",
      "  Step 14: Select Pivot = 43\n",
      "  Step 15: Compare [3] with Pivot\n",
      "  Step 16: Compare [4] with Pivot\n",
      "  Step 17: Compare [5] with Pivot\n",
      "  Step 18: Pivot Placed at [5]\n",
      "  Step 19: Select Pivot = 27\n",
      "  Step 20: Compare [3] with Pivot\n",
      "  Step 21: Pivot Placed at [3]\n",
      "  Step 22: Sorting Complete\n"
     ]
    }
   ],
   "source": [
    "# Default: sort [38, 27, 43, 3, 9, 82, 10]\n",
    "steps = eigenvue.steps(\"quicksort\")\n",
    "print(f\"QuickSort — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Merge Sort\n",
    "\n",
    "Stable divide-and-conquer sort that merges sorted sub-arrays.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `merge-sort` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(n log n) |\n",
    "| **Space** | O(n) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge Sort — 31 steps\n",
      "\n",
      "  Step  0: Initialize Merge Sort\n",
      "  Step  1: Round 1: Merge Sub-arrays of Size 1\n",
      "  Step  2: Merge [0..0] and [1..1]\n",
      "  Step  3: Pick 27 from Right\n",
      "  Step  4: Merge Complete: [0..1]\n",
      "  Step  5: Merge [2..2] and [3..3]\n",
      "  Step  6: Pick 3 from Right\n",
      "  Step  7: Merge Complete: [2..3]\n",
      "  Step  8: Merge [4..4] and [5..5]\n",
      "  Step  9: Pick 9 from Left\n",
      "  Step 10: Merge Complete: [4..5]\n",
      "  Step 11: Round 2: Merge Sub-arrays of Size 2\n",
      "  Step 12: Merge [0..1] and [2..3]\n",
      "  Step 13: Pick 3 from Right\n",
      "  Step 14: Pick 27 from Left\n",
      "  Step 15: Pick 38 from Left\n",
      "  Step 16: Merge Complete: [0..3]\n",
      "  Step 17: Merge [4..5] and [6..6]\n",
      "  Step 18: Pick 9 from Left\n",
      "  Step 19: Pick 10 from Right\n",
      "  Step 20: Merge Complete: [4..6]\n",
      "  Step 21: Round 3: Merge Sub-arrays of Size 4\n",
      "  Step 22: Merge [0..3] and [4..6]\n",
      "  Step 23: Pick 3 from Left\n",
      "  Step 24: Pick 9 from Right\n",
      "  Step 25: Pick 10 from Right\n",
      "  Step 26: Pick 27 from Left\n",
      "  Step 27: Pick 38 from Left\n",
      "  Step 28: Pick 43 from Left\n",
      "  Step 29: Merge Complete: [0..6]\n",
      "  Step 30: Sorting Complete\n"
     ]
    }
   ],
   "source": [
    "# Default: sort [38, 27, 43, 3, 9, 82, 10]\n",
    "steps = eigenvue.steps(\"merge-sort\")\n",
    "print(f\"Merge Sort — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Breadth-First Search (BFS)\n",
    "\n",
    "Explore a graph level by level using a queue.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `bfs` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(V + E) |\n",
    "| **Space** | O(V) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS — 10 steps\n",
      "\n",
      "  Step  0: Initialize BFS                       queue=['A']  visited=['A']\n",
      "  Step  1: Dequeue \"A\"                          queue=[]  visited=['A']\n",
      "  Step  2: Visit \"B\"                            queue=['B']  visited=['A', 'B']\n",
      "  Step  3: Visit \"C\"                            queue=['B', 'C']  visited=['A', 'B', 'C']\n",
      "  Step  4: Dequeue \"B\"                          queue=['C']  visited=['A', 'B', 'C']\n",
      "  Step  5: Visit \"D\"                            queue=['C', 'D']  visited=['A', 'B', 'C', 'D']\n",
      "  Step  6: Visit \"E\"                            queue=['C', 'D', 'E']  visited=['A', 'B', 'C', 'D', 'E']\n",
      "  Step  7: Dequeue \"C\"                          queue=['D', 'E']  visited=['A', 'B', 'C', 'D', 'E']\n",
      "  Step  8: Visit \"F\"                            queue=['D', 'E', 'F']  visited=['A', 'B', 'C', 'D', 'E', 'F']\n",
      "  Step  9: Target \"F\" Found!                    queue=[]  visited=['A', 'B', 'C', 'D', 'E', 'F']\n"
     ]
    }
   ],
   "source": [
    "# Default: BFS on a 6-node graph from A to F\n",
    "steps = eigenvue.steps(\"bfs\")\n",
    "print(f\"BFS — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    state = s[\"state\"]\n",
    "    queue = state.get(\"queue\", [])\n",
    "    visited = state.get(\"visited\", [])\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']:<35s}  queue={queue}  visited={visited}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Depth-First Search (DFS)\n",
    "\n",
    "Explore a graph by going as deep as possible before backtracking.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `dfs` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(V + E) |\n",
    "| **Space** | O(V) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS — 10 steps\n",
      "\n",
      "  Step  0: Initialize DFS                       stack=['A']  visited=[]\n",
      "  Step  1: Visit \"A\"                            stack=[]  visited=['A']\n",
      "  Step  2: Push Neighbors of \"A\"                stack=['C', 'B']  visited=['A']\n",
      "  Step  3: Visit \"B\"                            stack=['C']  visited=['A', 'B']\n",
      "  Step  4: Push Neighbors of \"B\"                stack=['C', 'E', 'D']  visited=['A', 'B']\n",
      "  Step  5: Visit \"D\"                            stack=['C', 'E']  visited=['A', 'B', 'D']\n",
      "  Step  6: Visit \"E\"                            stack=['C']  visited=['A', 'B', 'D', 'E']\n",
      "  Step  7: Push Neighbors of \"E\"                stack=['C', 'F']  visited=['A', 'B', 'D', 'E']\n",
      "  Step  8: Visit \"F\"                            stack=['C']  visited=['A', 'B', 'D', 'E', 'F']\n",
      "  Step  9: Target \"F\" Found!                    stack=[]  visited=['A', 'B', 'D', 'E', 'F']\n"
     ]
    }
   ],
   "source": [
    "# Default: DFS on a 6-node graph from A to F\n",
    "steps = eigenvue.steps(\"dfs\")\n",
    "print(f\"DFS — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    state = s[\"state\"]\n",
    "    stack = state.get(\"stack\", [])\n",
    "    visited = state.get(\"visited\", [])\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']:<35s}  stack={stack}  visited={visited}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 Dijkstra's Shortest Path\n",
    "\n",
    "Find shortest paths between nodes in a weighted graph using a greedy approach.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `dijkstra` |\n",
    "| **Difficulty** | Advanced |\n",
    "| **Time** | O((V + E) log V) |\n",
    "| **Space** | O(V) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dijkstra — 21 steps\n",
      "\n",
      "  Step  0: Initialize Dijkstra's Algorithm           current=  distances={'A': 0, 'B': '∞', 'C': '∞', 'D': '∞', 'E': '∞'}\n",
      "  Step  1: Process \"A\" (dist = 0)                    current=  distances={'A': 0, 'B': '∞', 'C': '∞', 'D': '∞', 'E': '∞'}\n",
      "  Step  2: Relax Edge A → B                          current=  distances={'A': 0, 'B': '∞', 'C': '∞', 'D': '∞', 'E': '∞'}\n",
      "  Step  3: Update dist[B] = 4.0                      current=  distances={'A': 0, 'B': 4.0, 'C': '∞', 'D': '∞', 'E': '∞'}\n",
      "  Step  4: Relax Edge A → C                          current=  distances={'A': 0, 'B': 4.0, 'C': '∞', 'D': '∞', 'E': '∞'}\n",
      "  Step  5: Update dist[C] = 2.0                      current=  distances={'A': 0, 'B': 4.0, 'C': 2.0, 'D': '∞', 'E': '∞'}\n",
      "  Step  6: Process \"C\" (dist = 2.0)                  current=  distances={'A': 0, 'B': 4.0, 'C': 2.0, 'D': '∞', 'E': '∞'}\n",
      "  Step  7: Relax Edge C → B                          current=  distances={'A': 0, 'B': 4.0, 'C': 2.0, 'D': '∞', 'E': '∞'}\n",
      "  Step  8: Update dist[B] = 3.0                      current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': '∞', 'E': '∞'}\n",
      "  Step  9: Relax Edge C → D                          current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': '∞', 'E': '∞'}\n",
      "  Step 10: Update dist[D] = 10.0                     current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 10.0, 'E': '∞'}\n",
      "  Step 11: Relax Edge C → E                          current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 10.0, 'E': '∞'}\n",
      "  Step 12: Update dist[E] = 12.0                     current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 10.0, 'E': 12.0}\n",
      "  Step 13: Process \"B\" (dist = 3.0)                  current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 10.0, 'E': 12.0}\n",
      "  Step 14: Relax Edge B → D                          current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 10.0, 'E': 12.0}\n",
      "  Step 15: Update dist[D] = 8.0                      current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 8.0, 'E': 12.0}\n",
      "  Step 16: Process \"D\" (dist = 8.0)                  current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 8.0, 'E': 12.0}\n",
      "  Step 17: Relax Edge D → E                          current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 8.0, 'E': 12.0}\n",
      "  Step 18: Update dist[E] = 10.0                     current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 8.0, 'E': 10.0}\n",
      "  Step 19: Process \"E\" (dist = 10.0)                 current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 8.0, 'E': 10.0}\n",
      "  Step 20: Shortest Path to \"E\" Found!               current=  distances={'A': 0, 'B': 3.0, 'C': 2.0, 'D': 8.0, 'E': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Default: shortest path from A to E in a 5-node weighted graph\n",
    "steps = eigenvue.steps(\"dijkstra\")\n",
    "print(f\"Dijkstra — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    state = s[\"state\"]\n",
    "    distances = state.get(\"distances\", {})\n",
    "    current = state.get(\"currentNode\", \"\")\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']:<40s}  current={current}  distances={distances}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Deep Learning Algorithms\n",
    "\n",
    "Eigenvue includes **5 deep learning algorithms** that walk through the fundamental building blocks of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Perceptron\n",
    "\n",
    "The simplest neural network: a single neuron that performs weighted sum + activation.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `perceptron` |\n",
    "| **Difficulty** | Beginner |\n",
    "| **Time** | O(n × d) |\n",
    "| **Space** | O(d) |\n",
    "\n",
    "Supports three activation functions: `\"step\"`, `\"sigmoid\"`, `\"relu\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron — 6 steps\n",
      "\n",
      "  Step 0: Input Values\n",
      "           The neuron receives 3 inputs: [0.5, -0.3, 0.8]. Each input represents a feature or signal fed into the neuron.\n",
      "\n",
      "  Step 1: Weight Values\n",
      "           Each input has a corresponding weight: [0.4, 0.7, -0.2]. Weights control how much influence each input has on the output\n",
      "\n",
      "  Step 2: Weighted Inputs (wᵢ × xᵢ)\n",
      "           Multiply each input by its weight: 0.4 × 0.5 = 0.2, 0.7 × -0.3 = -0.21, -0.2 × 0.8 = -0.16000000000000003. These product\n",
      "\n",
      "  Step 3: Pre-activation: z = -0.0700\n",
      "           Sum all weighted inputs and add the bias: z = (0.2 + -0.21 + -0.16000000000000003) + 0.1 = -0.0700. The bias shifts the \n",
      "\n",
      "  Step 4: Activation: step(-0.0700) = 0.0000\n",
      "           Apply the step activation function to z = -0.0700. Result: step(-0.0700) = 0.0000. The activation function introduces no\n",
      "\n",
      "  Step 5: Output: 0.0000\n",
      "           The neuron's final output is 0.0000. This value would be passed to the next layer in a neural network, or used directly \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default: inputs=[0.5, -0.3, 0.8], weights=[0.4, 0.7, -0.2], bias=0.1, activation=\"step\"\n",
    "steps = eigenvue.steps(\"perceptron\")\n",
    "print(f\"Perceptron — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    print(f\"  Step {s['index']}: {s['title']}\")\n",
    "    print(f\"           {s['explanation'][:120]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron (sigmoid) — 6 steps\n",
      "  Output: 0.574442516811659\n"
     ]
    }
   ],
   "source": [
    "# Try with sigmoid activation\n",
    "steps_sigmoid = eigenvue.steps(\n",
    "    \"perceptron\",\n",
    "    inputs={\n",
    "        \"inputs\": [1.0, 0.5],\n",
    "        \"weights\": [0.6, -0.4],\n",
    "        \"bias\": -0.1,\n",
    "        \"activationFunction\": \"sigmoid\"\n",
    "    }\n",
    ")\n",
    "print(f\"Perceptron (sigmoid) — {len(steps_sigmoid)} steps\")\n",
    "\n",
    "# Show the final output\n",
    "final_state = steps_sigmoid[-1][\"state\"]\n",
    "print(f\"  Output: {final_state.get('output', final_state)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Feedforward Neural Network\n",
    "\n",
    "Multi-layer neural network: signals propagate forward through layers.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `feedforward-network` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(Σ n_l × n_{l+1}) |\n",
    "| **Space** | O(Σ n_l × n_{l+1}) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward Network — 4 steps\n",
      "\n",
      "  Step  0: Network Architecture\n",
      "  Step  1: Forward Propagation → Hidden Layer 1\n",
      "  Step  2: Forward Propagation → Output Layer\n",
      "  Step  3: Network Output\n"
     ]
    }
   ],
   "source": [
    "# Default: 2→3→1 network with sigmoid activation\n",
    "steps = eigenvue.steps(\"feedforward-network\")\n",
    "print(f\"Feedforward Network — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Backpropagation\n",
    "\n",
    "How neural networks learn: computing gradients through the chain rule.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `backpropagation` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(Σ n_l × n_{l+1}) |\n",
    "| **Space** | O(Σ n_l × n_{l+1}) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropagation — 9 steps\n",
      "\n",
      "  Step  0: Forward Pass Begins [forward]\n",
      "  Step  1: Forward: Layer 1 [forward]\n",
      "  Step  2: Forward: Layer 2 [forward]\n",
      "  Step  3: Compute Loss [loss]\n",
      "  Step  4: Backward: Output Layer Gradients [backward]\n",
      "  Step  5: Backward: Hidden Layer 1 [backward]\n",
      "  Step  6: Update Weights: Layer 1 [update]\n",
      "  Step  7: Update Weights: Layer 2 [update]\n",
      "  Step  8: Training Step Complete [complete]\n"
     ]
    }
   ],
   "source": [
    "# Default: 2→2→1 network, inputs=[0.5, 0.8], target=[1], lr=0.1\n",
    "steps = eigenvue.steps(\"backpropagation\")\n",
    "print(f\"Backpropagation — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    phase = s.get(\"phase\", \"\")\n",
    "    phase_str = f\" [{phase}]\" if phase else \"\"\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}{phase_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Convolution (2D)\n",
    "\n",
    "How CNNs detect features: sliding a kernel across an input grid.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `convolution` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(H × W × K² × C) |\n",
    "| **Space** | O(H × W + K²) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Convolution — 11 steps\n",
      "\n",
      "  Step  0: Input Grid & Kernel\n",
      "  Step  1: Position (0, 0): Sum = -4.0\n",
      "  Step  2: Position (0, 1): Sum = -4.0\n",
      "  Step  3: Position (0, 2): Sum = 2.0\n",
      "  Step  4: Position (1, 0): Sum = -4.0\n",
      "  Step  5: Position (1, 1): Sum = -4.0\n",
      "  Step  6: Position (1, 2): Sum = 4.0\n",
      "  Step  7: Position (2, 0): Sum = 6.0\n",
      "  Step  8: Position (2, 1): Sum = 6.0\n",
      "  Step  9: Position (2, 2): Sum = 6.0\n",
      "  Step 10: Convolution Complete\n"
     ]
    }
   ],
   "source": [
    "# Default: 4×4 input, 2×2 kernel\n",
    "steps = eigenvue.steps(\"convolution\")\n",
    "print(f\"2D Convolution — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}\")\n",
    "\n",
    "# Show the final output matrix\n",
    "final_state = steps[-1][\"state\"]\n",
    "if \"output\" in final_state:\n",
    "    print(f\"\\n  Output matrix: {final_state['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Gradient Descent\n",
    "\n",
    "Optimization by following the steepest downhill direction on the loss landscape.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `gradient-descent` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(T × d) |\n",
    "| **Space** | O(d) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent — 21 steps\n",
      "\n",
      "  Step  0: Initial Position                     x=?, y=?, loss=36\n",
      "  Step  1: Step 1: Loss = 10.0800               x=?, y=?, loss=10.079999999999998\n",
      "  Step  2: Step 2: Loss = 4.3776                x=?, y=?, loss=4.3776\n",
      "  Step  3: Step 3: Loss = 2.4699                x=?, y=?, loss=2.469888\n",
      "  Step  4: Step 4: Loss = 1.5276                x=?, y=?, loss=1.5276441600000001\n",
      "  Step  5: Step 5: Loss = 0.9692                x=?, y=?, loss=0.9691987968000002\n",
      "  Step  6: Step 6: Loss = 0.6189                x=?, y=?, loss=0.6189282754560002\n",
      "  Step  7: Step 7: Loss = 0.3959                x=?, y=?, loss=0.3958966635724801\n",
      "  Step  8: Step 8: Loss = 0.2533                x=?, y=?, loss=0.25333907545128964\n",
      "  Step  9: Step 9: Loss = 0.1621                x=?, y=?, loss=0.16213144201120977\n",
      "  Step 10: Step 10: Loss = 0.1038               x=?, y=?, loss=0.10376323228275576\n",
      "  Step 11: Step 11: Loss = 0.0664               x=?, y=?, loss=0.06640832616425674\n",
      "  Step 12: Step 12: Loss = 0.0425               x=?, y=?, loss=0.0425013059456512\n",
      "  Step 13: Step 13: Loss = 0.0272               x=?, y=?, loss=0.027200832157301062\n",
      "  Step 14: Step 14: Loss = 0.0174               x=?, y=?, loss=0.01740853199700617\n",
      "  Step 15: Step 15: Loss = 0.0111               x=?, y=?, loss=0.011141460384697308\n",
      "  Step 16: Step 16: Loss = 0.0071               x=?, y=?, loss=0.007130534631264413\n",
      "  Step 17: Step 17: Loss = 0.0046               x=?, y=?, loss=0.004563542161618527\n",
      "  Step 18: Step 18: Loss = 0.0029               x=?, y=?, loss=0.0029206669830533455\n",
      "  Step 19: Step 19: Loss = 0.0019               x=?, y=?, loss=0.001869226869092939\n",
      "  Step 20: Step 20: Loss = 0.0012               x=?, y=?, loss=0.0011963051962096886\n"
     ]
    }
   ],
   "source": [
    "# Default: SGD optimizer, lr=0.1, 20 steps from (3, 3)\n",
    "steps = eigenvue.steps(\"gradient-descent\")\n",
    "print(f\"Gradient Descent — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    state = s[\"state\"]\n",
    "    x = state.get(\"x\", state.get(\"currentX\", \"?\"))\n",
    "    y = state.get(\"y\", state.get(\"currentY\", \"?\"))\n",
    "    loss = state.get(\"loss\", state.get(\"currentLoss\", \"?\"))\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']:<35s}  x={x}, y={y}, loss={loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Generative AI / Transformers\n",
    "\n",
    "Eigenvue includes **5 generative AI algorithms** that decompose the Transformer architecture — the engine behind GPT, BERT, and modern LLMs — into understandable, visual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 BPE Tokenization\n",
    "\n",
    "Break text into subword tokens using Byte-Pair Encoding merge rules.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `tokenization-bpe` |\n",
    "| **Difficulty** | Beginner |\n",
    "| **Time** | O(n × m) |\n",
    "| **Space** | O(n) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE Tokenization — 12 steps\n",
      "\n",
      "  Step  0: Split Into Characters                     tokens=['l', 'o', 'w', 'e', 's', 't']\n",
      "  Step  1: Merge: \"l\" + \"o\" → \"lo\"                   tokens=['l', 'o', 'w', 'e', 's', 't']\n",
      "  Step  2: After Merge 1                             tokens=['lo', 'w', 'e', 's', 't']\n",
      "  Step  3: Merge: \"lo\" + \"w\" → \"low\"                 tokens=['lo', 'w', 'e', 's', 't']\n",
      "  Step  4: After Merge 1                             tokens=['low', 'e', 's', 't']\n",
      "  Step  5: Merge: \"e\" + \"s\" → \"es\"                   tokens=['low', 'e', 's', 't']\n",
      "  Step  6: After Merge 1                             tokens=['low', 'es', 't']\n",
      "  Step  7: Merge: \"es\" + \"t\" → \"est\"                 tokens=['low', 'es', 't']\n",
      "  Step  8: After Merge 1                             tokens=['low', 'est']\n",
      "  Step  9: Merge: \"low\" + \"est\" → \"lowest\"           tokens=['low', 'est']\n",
      "  Step 10: After Merge 1                             tokens=['lowest']\n",
      "  Step 11: Tokenization Complete                     tokens=['lowest']\n"
     ]
    }
   ],
   "source": [
    "# Default: tokenize \"lowest\" using BPE merge rules\n",
    "steps = eigenvue.steps(\"tokenization-bpe\")\n",
    "print(f\"BPE Tokenization — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    state = s[\"state\"]\n",
    "    tokens = state.get(\"tokens\", state.get(\"currentTokens\", []))\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']:<40s}  tokens={tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Token Embeddings\n",
    "\n",
    "Map tokens to dense numerical vectors using an embedding lookup table.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `token-embeddings` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(n × d) |\n",
    "| **Space** | O(V × d) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings — 8 steps\n",
      "\n",
      "  Step  0: Input Token Sequence\n",
      "           We have 3 tokens: [\"The\", \"cat\", \"sat\"]. Each token will be mapped to a 4-dimensional embedding vector.\n",
      "\n",
      "  Step  1: Embed Token: \"The\"\n",
      "           Looking up the embedding for token \"The\" (index 0). The embedding table returns a 4-dimensional vector: [0.863, 0.338, -\n",
      "\n",
      "  Step  2: Embed Token: \"cat\"\n",
      "           Looking up the embedding for token \"cat\" (index 1). The embedding table returns a 4-dimensional vector: [0.197, -0.713, \n",
      "\n",
      "  Step  3: Embed Token: \"sat\"\n",
      "           Looking up the embedding for token \"sat\" (index 2). The embedding table returns a 4-dimensional vector: [0.427, -0.389, \n",
      "\n",
      "  Step  4: Similarity: \"The\" ↔ \"cat\"\n",
      "           Computing cosine similarity between \"The\" and \"cat\": cos(θ) = (A · B) / (‖A‖ × ‖B‖) = 0.3364. These embeddings point in \n",
      "\n",
      "  Step  5: Similarity: \"The\" ↔ \"sat\"\n",
      "           Computing cosine similarity between \"The\" and \"sat\": cos(θ) = (A · B) / (‖A‖ × ‖B‖) = 0.4460. These embeddings point in \n",
      "\n",
      "  Step  6: Similarity: \"cat\" ↔ \"sat\"\n",
      "           Computing cosine similarity between \"cat\" and \"sat\": cos(θ) = (A · B) / (‖A‖ × ‖B‖) = 0.8198. These embeddings point in \n",
      "\n",
      "  Step  7: Embedding Complete\n",
      "           All 3 tokens have been embedded into 4-dimensional vectors. These vectors are the input to the self-attention mechanism.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Default: embed [\"The\", \"cat\", \"sat\"] into 4-dimensional vectors\n",
    "steps = eigenvue.steps(\"token-embeddings\")\n",
    "print(f\"Token Embeddings — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}\")\n",
    "    print(f\"           {s['explanation'][:120]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Self-Attention (Scaled Dot-Product)\n",
    "\n",
    "The core mechanism inside Transformer models — watch how each token decides which other tokens to attend to.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `self-attention` |\n",
    "| **Difficulty** | Intermediate |\n",
    "| **Time** | O(n² × d) |\n",
    "| **Space** | O(n² + n × d) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Attention — 11 steps\n",
      "\n",
      "  Step  0: Input Embeddings [input]\n",
      "  Step  1: Compute Query Matrix (Q) [projection]\n",
      "  Step  2: Compute Key Matrix (K) [projection]\n",
      "  Step  3: Compute Value Matrix (V) [projection]\n",
      "  Step  4: Compute Attention Scores (Q × Kᵀ) [scores]\n",
      "  Step  5: Scale by 1/√d_k = 1/√4 ≈ 0.5000 [scaling]\n",
      "  Step  6: Apply Softmax (Row-wise) [softmax]\n",
      "  Step  7: \"The\" Attends To... [output]\n",
      "  Step  8: \"cat\" Attends To... [output]\n",
      "  Step  9: \"sat\" Attends To... [output]\n",
      "  Step 10: Self-Attention Complete [result]\n"
     ]
    }
   ],
   "source": [
    "# Default: self-attention over [\"The\", \"cat\", \"sat\"] with embeddingDim=4\n",
    "steps = eigenvue.steps(\"self-attention\")\n",
    "print(f\"Self-Attention — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    phase = s.get(\"phase\", \"\")\n",
    "    phase_str = f\" [{phase}]\" if phase else \"\"\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}{phase_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Attention on ['I', 'love', 'AI'] (dim=3) — 11 steps\n",
      "\n",
      "  Attention weight matrix:\n",
      "    [0.3176, 0.3791, 0.3033]\n",
      "    [0.3459, 0.3355, 0.3186]\n",
      "    [0.3243, 0.2913, 0.3844]\n"
     ]
    }
   ],
   "source": [
    "# Custom: different sentence\n",
    "steps = eigenvue.steps(\n",
    "    \"self-attention\",\n",
    "    inputs={\"tokens\": [\"I\", \"love\", \"AI\"], \"embeddingDim\": 3}\n",
    ")\n",
    "print(f\"Self-Attention on ['I', 'love', 'AI'] (dim=3) — {len(steps)} steps\")\n",
    "\n",
    "# Show the attention weights from the final step\n",
    "final_state = steps[-1][\"state\"]\n",
    "if \"attentionWeights\" in final_state:\n",
    "    print(f\"\\n  Attention weight matrix:\")\n",
    "    for row in final_state[\"attentionWeights\"]:\n",
    "        print(f\"    {[round(v, 4) for v in row]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Multi-Head Attention\n",
    "\n",
    "See how multiple attention heads capture different relationships simultaneously.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `multi-head-attention` |\n",
    "| **Difficulty** | Advanced |\n",
    "| **Time** | O(h × n² × d_k) |\n",
    "| **Space** | O(h × n² + n × d) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Head Attention — 13 steps\n",
      "\n",
      "  Step  0: Input Embeddings [initialization]\n",
      "  Step  1: Splitting Into 2 Heads [initialization]\n",
      "  Step  2: Head 1: Q, K, V Projections [head-0]\n",
      "  Step  3: Head 1: Attention Scores [head-0]\n",
      "  Step  4: Head 1: Attention Weights [head-0]\n",
      "  Step  5: Head 1: Weighted Output [head-0]\n",
      "  Step  6: Head 2: Q, K, V Projections [head-1]\n",
      "  Step  7: Head 2: Attention Scores [head-1]\n",
      "  Step  8: Head 2: Attention Weights [head-1]\n",
      "  Step  9: Head 2: Weighted Output [head-1]\n",
      "  Step 10: Concatenate All Heads [concatenation]\n",
      "  Step 11: Final Linear Projection (W_O) [projection]\n",
      "  Step 12: Multi-Head Attention Complete [result]\n"
     ]
    }
   ],
   "source": [
    "# Default: [\"The\", \"cat\", \"sat\", \"on\"], embeddingDim=8, numHeads=2\n",
    "steps = eigenvue.steps(\"multi-head-attention\")\n",
    "print(f\"Multi-Head Attention — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    phase = s.get(\"phase\", \"\")\n",
    "    phase_str = f\" [{phase}]\" if phase else \"\"\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}{phase_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Transformer Block\n",
    "\n",
    "Follow data through a complete transformer encoder block step by step: attention, residual connections, layer normalization, and feed-forward network.\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **ID** | `transformer-block` |\n",
    "| **Difficulty** | Advanced |\n",
    "| **Time** | O(n² × d + n × d × d_ff) |\n",
    "| **Space** | O(n² + n × d_ff) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Block — 11 steps\n",
      "\n",
      "  Step  0: Input Embeddings [input]\n",
      "  Step  1: Self-Attention: Computing [self-attention]\n",
      "  Step  2: Self-Attention: Output [self-attention]\n",
      "  Step  3: Residual Connection + Add [add-norm-1]\n",
      "  Step  4: Layer Normalization [add-norm-1]\n",
      "  Step  5: Feed-Forward Network: Computing [ffn]\n",
      "  Step  6: FFN: ReLU(x × W₁ + b₁) [ffn]\n",
      "  Step  7: FFN: × W₂ + b₂ [ffn]\n",
      "  Step  8: Residual Connection + Add [add-norm-2]\n",
      "  Step  9: Layer Normalization [add-norm-2]\n",
      "  Step 10: Transformer Block Complete [result]\n"
     ]
    }
   ],
   "source": [
    "# Default: [\"The\", \"cat\", \"sat\"], embeddingDim=4, ffnDim=8, numHeads=1\n",
    "steps = eigenvue.steps(\"transformer-block\")\n",
    "print(f\"Transformer Block — {len(steps)} steps\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    phase = s.get(\"phase\", \"\")\n",
    "    phase_str = f\" [{phase}]\" if phase else \"\"\n",
    "    print(f\"  Step {s['index']:>2d}: {s['title']}{phase_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Custom Inputs\n",
    "\n",
    "Every algorithm accepts custom inputs via the `inputs` parameter. When omitted (`None`), the algorithm's built-in defaults are used. This section demonstrates customization for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Custom Sorting Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuickSort on [100, 42, 7, 55, 23, 88, 1] — 32 steps\n",
      "  Final array: [1, 7, 23, 42, 55, 88, 100]\n"
     ]
    }
   ],
   "source": [
    "# QuickSort with a custom array\n",
    "steps = eigenvue.steps(\"quicksort\", inputs={\"array\": [100, 42, 7, 55, 23, 88, 1]})\n",
    "print(f\"QuickSort on [100, 42, 7, 55, 23, 88, 1] — {len(steps)} steps\")\n",
    "print(f\"  Final array: {steps[-1]['state'].get('array', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Custom Search Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 5 in [2, 4, 6, 8, 10, 12, 14]\n",
      "  Steps: 8\n",
      "  Final step: Target Not Found\n",
      "  Result: -1\n"
     ]
    }
   ],
   "source": [
    "# Binary search — target not found\n",
    "steps = eigenvue.steps(\n",
    "    \"binary-search\",\n",
    "    inputs={\"array\": [2, 4, 6, 8, 10, 12, 14], \"target\": 5}\n",
    ")\n",
    "print(f\"Searching for 5 in [2, 4, 6, 8, 10, 12, 14]\")\n",
    "print(f\"  Steps: {len(steps)}\")\n",
    "print(f\"  Final step: {steps[-1]['title']}\")\n",
    "print(f\"  Result: {steps[-1]['state'].get('result', steps[-1]['state'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Custom Graph Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS on custom graph (X→W) — 7 steps\n"
     ]
    }
   ],
   "source": [
    "# BFS on a custom graph\n",
    "steps = eigenvue.steps(\"bfs\", inputs={\n",
    "    \"adjacencyList\": {\n",
    "        \"X\": [\"Y\", \"Z\"],\n",
    "        \"Y\": [\"X\", \"W\"],\n",
    "        \"Z\": [\"X\", \"W\"],\n",
    "        \"W\": [\"Y\", \"Z\"]\n",
    "    },\n",
    "    \"positions\": {\n",
    "        \"X\": {\"x\": 0.1, \"y\": 0.5},\n",
    "        \"Y\": {\"x\": 0.5, \"y\": 0.2},\n",
    "        \"Z\": {\"x\": 0.5, \"y\": 0.8},\n",
    "        \"W\": {\"x\": 0.9, \"y\": 0.5}\n",
    "    },\n",
    "    \"startNode\": \"X\",\n",
    "    \"targetNode\": \"W\"\n",
    "})\n",
    "print(f\"BFS on custom graph (X→W) — {len(steps)} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Custom Neural Network Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron (ReLU) — 6 steps\n",
      "  Final state: {'inputs': [2.0, -1.0, 0.5], 'weights': [0.3, 0.8, -0.5], 'bias': 0.2, 'activationFunction': 'relu', 'n': 3, 'weightedInputs': [0.6, -0.8, -0.25], 'z': -0.25000000000000006, 'a': 0.0, 'output': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Perceptron with ReLU activation\n",
    "steps = eigenvue.steps(\"perceptron\", inputs={\n",
    "    \"inputs\": [2.0, -1.0, 0.5],\n",
    "    \"weights\": [0.3, 0.8, -0.5],\n",
    "    \"bias\": 0.2,\n",
    "    \"activationFunction\": \"relu\"\n",
    "})\n",
    "print(f\"Perceptron (ReLU) — {len(steps)} steps\")\n",
    "print(f\"  Final state: {steps[-1]['state']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward [3→4→2] — 4 steps\n"
     ]
    }
   ],
   "source": [
    "# Feedforward network with custom architecture\n",
    "steps = eigenvue.steps(\"feedforward-network\", inputs={\n",
    "    \"layerSizes\": [3, 4, 2],\n",
    "    \"inputValues\": [0.1, 0.5, 0.9],\n",
    "    \"activationFunction\": \"sigmoid\"\n",
    "})\n",
    "print(f\"Feedforward [3→4→2] — {len(steps)} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 Custom Convolution Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution (3×3 input, 2×2 kernel) — 6 steps\n"
     ]
    }
   ],
   "source": [
    "# 3×3 input with a 2×2 edge-detection kernel\n",
    "steps = eigenvue.steps(\"convolution\", inputs={\n",
    "    \"input\": [\n",
    "        [0, 1, 2],\n",
    "        [3, 4, 5],\n",
    "        [6, 7, 8]\n",
    "    ],\n",
    "    \"kernel\": [\n",
    "        [1, -1],\n",
    "        [-1, 1]\n",
    "    ]\n",
    "})\n",
    "print(f\"Convolution (3×3 input, 2×2 kernel) — {len(steps)} steps\")\n",
    "if \"output\" in steps[-1][\"state\"]:\n",
    "    print(f\"  Output: {steps[-1]['state']['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6 Custom Transformer Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Attention on 5 tokens — 13 steps\n"
     ]
    }
   ],
   "source": [
    "# Self-attention with a longer sequence\n",
    "steps = eigenvue.steps(\"self-attention\", inputs={\n",
    "    \"tokens\": [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\"],\n",
    "    \"embeddingDim\": 4\n",
    "})\n",
    "print(f\"Self-Attention on 5 tokens — {len(steps)} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Head Attention (4 heads) on 5 tokens — 21 steps\n"
     ]
    }
   ],
   "source": [
    "# Multi-head attention with 4 heads\n",
    "steps = eigenvue.steps(\"multi-head-attention\", inputs={\n",
    "    \"tokens\": [\"Attention\", \"is\", \"all\", \"you\", \"need\"],\n",
    "    \"embeddingDim\": 8,\n",
    "    \"numHeads\": 4\n",
    "})\n",
    "print(f\"Multi-Head Attention (4 heads) on 5 tokens — {len(steps)} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Block (ffnDim=16) — 11 steps\n"
     ]
    }
   ],
   "source": [
    "# Transformer block with larger FFN\n",
    "steps = eigenvue.steps(\"transformer-block\", inputs={\n",
    "    \"tokens\": [\"Hello\", \"world\"],\n",
    "    \"embeddingDim\": 4,\n",
    "    \"ffnDim\": 16,\n",
    "    \"numHeads\": 1\n",
    "})\n",
    "print(f\"Transformer Block (ffnDim=16) — {len(steps)} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Step Data Deep Dive\n",
    "\n",
    "Each step dictionary returned by `eigenvue.steps()` follows a rigorous schema. This section examines every field in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Step Schema Overview\n",
    "\n",
    "| Field | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| `index` | `int` | 0-based position in the step sequence |\n",
    "| `id` | `str` | Step template identifier (e.g., `\"compare_mid\"`) |\n",
    "| `title` | `str` | Short human-readable heading |\n",
    "| `explanation` | `str` | Plain-language narration of the current operation |\n",
    "| `state` | `dict` | Snapshot of all algorithm variables at this point |\n",
    "| `visualActions` | `list[dict]` | Rendering instructions for the visualization engine |\n",
    "| `codeHighlight` | `dict` | Which source code lines correspond to this step |\n",
    "| `isTerminal` | `bool` | `True` only for the final step |\n",
    "| `phase` | `str` (optional) | Grouping label for UI phase indicators |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 2: Compute Key Matrix (K)\n",
      "======================================================================\n",
      "\n",
      "{\n",
      "  \"index\": 2,\n",
      "  \"id\": \"compute-k\",\n",
      "  \"title\": \"Compute Key Matrix (K)\",\n",
      "  \"explanation\": \"K = X \\u00d7 W_K. Each token's embedding is projected into \\\"key\\\" space. The key represents \\\"what does this token contain?\\\" Shape: [3, 4] \\u00d7 [4, 4] = [3, 4].\",\n",
      "  \"state\": {\n",
      "    \"tokens\": [\n",
      "      \"The\",\n",
      "      \"cat\",\n",
      "      \"sat\"\n",
      "    ],\n",
      "    \"K\": [\n",
      "      [\n",
      "        0.265067,\n",
      "        0.26862300000000006,\n",
      "        -0.26626900000000003,\n",
      "        -0.11705600000000002\n",
      "      ],\n",
      "      [\n",
      "        0.011884999999999979,\n",
      "        -0.34222300000000005,\n",
      "        0.015899000000000024,\n",
      "        0.261261\n",
      "      ],\n",
      "      [\n",
      "        0.031235,\n",
      "        0.211009,\n",
      "        -0.21606599999999998,\n",
      "        0.23782500000000006\n",
      "      ]\n",
      "    ],\n",
      "    \"W_K\": [\n",
      "      [\n",
      "        0.249,\n",
      "        -0.35,\n",
      "        0.1,\n",
      "        -0.107\n",
      "      ],\n",
      "      [\n",
      "        0.263,\n",
      "        0.384,\n",
      "        -0.309,\n",
      "        -0.118\n",
      "      ],\n",
      "      [\n",
      "        0.025,\n",
      "        -0.037,\n",
      "        -0.477,\n",
      "        0.399\n",
      "      ],\n",
      "      [\n",
      "        -0.1,\n",
      "        -0.23,\n",
      "        0.347,\n",
      "        0.076\n",
      "      ]\n",
      "    ],\n",
      "    \"phase\": \"projection\"\n",
      "  },\n",
      "  \"visualActions\": [\n",
      "    {\n",
      "      \"type\": \"showProjectionMatrix\",\n",
      "      \"projectionType\": \"K\",\n",
      "      \"matrix\": [\n",
      "        [\n",
      "          0.265067,\n",
      "          0.26862300000000006,\n",
      "          -0.26626900000000003,\n",
      "          -0.11705600000000002\n",
      "        ],\n",
      "        [\n",
      "          0.011884999999999979,\n",
      "          -0.34222300000000005,\n",
      "          0.015899000000000024,\n",
      "          0.261261\n",
      "        ],\n",
      "        [\n",
      "          0.031235,\n",
      "          0.211009,\n",
      "          -0.21606599999999998,\n",
      "          0.23782500000000006\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"showMessage\",\n",
      "      \"text\": \"K = X \\u00d7 W_K \\u2192 shape [3, 4]\",\n",
      "      \"messageType\": \"info\"\n",
      "    }\n",
      "  ],\n",
      "  \"codeHighlight\": {\n",
      "    \"language\": \"pseudocode\",\n",
      "    \"lines\": [\n",
      "      3\n",
      "    ]\n",
      "  },\n",
      "  \"isTerminal\": false,\n",
      "  \"phase\": \"projection\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Use a Self-Attention step for a rich example\n",
    "steps = eigenvue.steps(\"self-attention\")\n",
    "example_step = steps[2]  # Pick a step mid-execution\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"STEP {example_step['index']}: {example_step['title']}\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(json.dumps(example_step, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Examining State Snapshots\n",
    "\n",
    "The `state` field captures the algorithm's complete variable state at each step. The shape of this state differs by algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Search — state keys per step:\n",
      "\n",
      "  Step 0: ['array', 'target', 'left', 'right', 'result']\n",
      "  Step 1: ['array', 'target', 'left', 'right', 'mid', 'result']\n",
      "  Step 2: ['array', 'target', 'left', 'right', 'mid', 'result']\n",
      "  Step 3: ['array', 'target', 'left', 'right', 'mid', 'result']\n",
      "  Step 4: ['array', 'target', 'left', 'right', 'mid', 'result']\n"
     ]
    }
   ],
   "source": [
    "# Binary Search state: tracks pointers and array\n",
    "steps = eigenvue.steps(\"binary-search\")\n",
    "print(\"Binary Search — state keys per step:\\n\")\n",
    "\n",
    "for s in steps[:5]:  # Show first 5 steps\n",
    "    keys = list(s[\"state\"].keys())\n",
    "    print(f\"  Step {s['index']}: {keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Attention — state keys per step:\n",
      "\n",
      "  Step  0: ['tokens', 'embeddingDim', 'X', 'phase']\n",
      "  Step  1: ['tokens', 'Q', 'W_Q', 'phase']\n",
      "  Step  2: ['tokens', 'K', 'W_K', 'phase']\n",
      "  Step  3: ['tokens', 'V', 'W_V', 'phase']\n",
      "  Step  4: ['tokens', 'rawScores', 'phase']\n",
      "  Step  5: ['tokens', 'scaledScores', 'scaleFactor', 'phase']\n",
      "  Step  6: ['tokens', 'attentionWeights', 'phase']\n",
      "  Step  7: ['tokens', 'attentionWeights', 'currentQuery', 'queryWeights', 'contextVector', 'maxAttendedToken', 'maxWeight', 'phase']\n",
      "  Step  8: ['tokens', 'attentionWeights', 'currentQuery', 'queryWeights', 'contextVector', 'maxAttendedToken', 'maxWeight', 'phase']\n",
      "  Step  9: ['tokens', 'attentionWeights', 'currentQuery', 'queryWeights', 'contextVector', 'maxAttendedToken', 'maxWeight', 'phase']\n",
      "  Step 10: ['tokens', 'attentionWeights', 'output', 'phase']\n"
     ]
    }
   ],
   "source": [
    "# Self-Attention state: tracks matrices (Q, K, V, scores, weights, output)\n",
    "steps = eigenvue.steps(\"self-attention\")\n",
    "print(\"Self-Attention — state keys per step:\\n\")\n",
    "\n",
    "for s in steps:\n",
    "    keys = list(s[\"state\"].keys())\n",
    "    print(f\"  Step {s['index']:>2d}: {keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Visual Actions\n",
    "\n",
    "Each step includes `visualActions` — a list of rendering instructions that tell the visualization engine what to highlight, animate, or display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual actions in Binary Search:\n",
      "\n",
      "  Step 0: Initialize Search\n",
      "    → {'type': 'highlightRange', 'from': 0, 'to': 9, 'color': 'highlight'}\n",
      "    → {'type': 'movePointer', 'id': 'left', 'to': 0}\n",
      "    → {'type': 'movePointer', 'id': 'right', 'to': 9}\n",
      "\n",
      "  Step 1: Calculate Middle (Iteration 1)\n",
      "    → {'type': 'highlightRange', 'from': 0, 'to': 9, 'color': 'highlight'}\n",
      "    → {'type': 'highlightElement', 'index': 4, 'color': 'compare'}\n",
      "    → {'type': 'movePointer', 'id': 'left', 'to': 0}\n",
      "    → {'type': 'movePointer', 'id': 'right', 'to': 9}\n",
      "    → {'type': 'movePointer', 'id': 'mid', 'to': 4}\n",
      "\n",
      "  Step 2: Search Right Half\n",
      "    → {'type': 'dimRange', 'from': 0, 'to': 4}\n",
      "    → {'type': 'highlightRange', 'from': 5, 'to': 9, 'color': 'highlight'}\n",
      "    → {'type': 'movePointer', 'id': 'left', 'to': 5}\n",
      "    → {'type': 'movePointer', 'id': 'right', 'to': 9}\n",
      "    → {'type': 'movePointer', 'id': 'mid', 'to': 4}\n",
      "\n",
      "  Step 3: Calculate Middle (Iteration 2)\n",
      "    → {'type': 'highlightRange', 'from': 5, 'to': 9, 'color': 'highlight'}\n",
      "    → {'type': 'highlightElement', 'index': 7, 'color': 'compare'}\n",
      "    → {'type': 'movePointer', 'id': 'left', 'to': 5}\n",
      "    → {'type': 'movePointer', 'id': 'right', 'to': 9}\n",
      "    → {'type': 'movePointer', 'id': 'mid', 'to': 7}\n",
      "\n",
      "  Step 4: Search Left Half\n",
      "    → {'type': 'dimRange', 'from': 7, 'to': 9}\n",
      "    → {'type': 'highlightRange', 'from': 5, 'to': 6, 'color': 'highlight'}\n",
      "    → {'type': 'movePointer', 'id': 'left', 'to': 5}\n",
      "    → {'type': 'movePointer', 'id': 'right', 'to': 6}\n",
      "    → {'type': 'movePointer', 'id': 'mid', 'to': 7}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = eigenvue.steps(\"binary-search\")\n",
    "\n",
    "print(\"Visual actions in Binary Search:\\n\")\n",
    "for s in steps[:5]:\n",
    "    print(f\"  Step {s['index']}: {s['title']}\")\n",
    "    for action in s[\"visualActions\"]:\n",
    "        print(f\"    → {action}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 Code Highlights\n",
    "\n",
    "The `codeHighlight` field maps each step back to the relevant lines of source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code highlights in Binary Search:\n",
      "\n",
      "  Step 0: language=pseudocode, lines=[1, 2, 3]\n",
      "  Step 1: language=pseudocode, lines=[5, 6]\n",
      "  Step 2: language=pseudocode, lines=[10, 11]\n",
      "  Step 3: language=pseudocode, lines=[5, 6]\n",
      "  Step 4: language=pseudocode, lines=[12, 13]\n"
     ]
    }
   ],
   "source": [
    "steps = eigenvue.steps(\"binary-search\")\n",
    "\n",
    "print(\"Code highlights in Binary Search:\\n\")\n",
    "for s in steps[:5]:\n",
    "    ch = s[\"codeHighlight\"]\n",
    "    print(f\"  Step {s['index']}: language={ch['language']}, lines={ch['lines']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 Step Sequence Invariants\n",
    "\n",
    "Eigenvue enforces strict invariants on every step sequence:\n",
    "\n",
    "1. **Non-empty** — At least one step\n",
    "2. **Contiguous indices** — `steps[i][\"index\"] == i`\n",
    "3. **Exactly one terminal step** — Only the last step has `isTerminal == True`\n",
    "\n",
    "Let's verify these hold for every algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying step sequence invariants for ALL 17 algorithms:\n",
      "\n",
      "  binary-search             ✓  (  9 steps)\n",
      "  bfs                       ✓  ( 10 steps)\n",
      "  bubble-sort               ✓  ( 43 steps)\n",
      "  dfs                       ✓  ( 10 steps)\n",
      "  dijkstra                  ✓  ( 21 steps)\n",
      "  merge-sort                ✓  ( 31 steps)\n",
      "  quicksort                 ✓  ( 23 steps)\n",
      "  backpropagation           ✓  (  9 steps)\n",
      "  convolution               ✓  ( 11 steps)\n",
      "  feedforward-network       ✓  (  4 steps)\n",
      "  gradient-descent          ✓  ( 21 steps)\n",
      "  perceptron                ✓  (  6 steps)\n",
      "  tokenization-bpe          ✓  ( 12 steps)\n",
      "  multi-head-attention      ✓  ( 13 steps)\n",
      "  self-attention            ✓  ( 11 steps)\n",
      "  token-embeddings          ✓  (  8 steps)\n",
      "  transformer-block         ✓  ( 11 steps)\n",
      "\n",
      "All invariants verified successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying step sequence invariants for ALL 17 algorithms:\\n\")\n",
    "\n",
    "all_passed = True\n",
    "for algo in eigenvue.list():\n",
    "    steps = eigenvue.steps(algo.id)\n",
    "    \n",
    "    # Check non-empty\n",
    "    assert len(steps) > 0, f\"{algo.id}: empty step sequence\"\n",
    "    \n",
    "    # Check contiguous indices\n",
    "    for i, s in enumerate(steps):\n",
    "        assert s[\"index\"] == i, f\"{algo.id}: step {i} has index {s['index']}\"\n",
    "    \n",
    "    # Check terminal step\n",
    "    terminal_count = sum(1 for s in steps if s[\"isTerminal\"])\n",
    "    assert terminal_count == 1, f\"{algo.id}: {terminal_count} terminal steps\"\n",
    "    assert steps[-1][\"isTerminal\"], f\"{algo.id}: last step is not terminal\"\n",
    "    \n",
    "    print(f\"  {algo.id:<25s} ✓  ({len(steps):>3d} steps)\")\n",
    "\n",
    "print(\"\\nAll invariants verified successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.6 Deterministic Output\n",
    "\n",
    "Eigenvue generators are **deterministic** — the same inputs always produce identical step sequences. This is critical for reproducibility and cross-language parity with the TypeScript implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinism verified: two identical calls produce identical output.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Run the same algorithm twice and verify identical output\n",
    "steps_a = eigenvue.steps(\"self-attention\", inputs={\"tokens\": [\"a\", \"b\", \"c\"], \"embeddingDim\": 4})\n",
    "steps_b = eigenvue.steps(\"self-attention\", inputs={\"tokens\": [\"a\", \"b\", \"c\"], \"embeddingDim\": 4})\n",
    "\n",
    "# Deep comparison via JSON serialization\n",
    "assert json.dumps(steps_a, sort_keys=True) == json.dumps(steps_b, sort_keys=True)\n",
    "\n",
    "print(\"Determinism verified: two identical calls produce identical output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Error Handling\n",
    "\n",
    "Eigenvue raises clear, descriptive errors for invalid inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Invalid Algorithm ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Unknown algorithm 'nonexistent-algorithm'. Use eigenvue.list() to see available algorithms.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    eigenvue.steps(\"nonexistent-algorithm\")\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Invalid Category Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Invalid category 'invalid-category'. Valid categories: classical, deep-learning, generative-ai, quantum\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    eigenvue.list(category=\"invalid-category\")\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Missing Jupyter Dependency\n",
    "\n",
    "If `IPython` is not installed and you call `eigenvue.jupyter()`, the library raises a helpful `ImportError`:\n",
    "\n",
    "```python\n",
    "ImportError: IPython is required for Jupyter integration.\n",
    "Install it with: pip install eigenvue[jupyter]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Eigenvue provides a complete toolkit for visualizing and understanding algorithms:\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **17 Algorithms** | Classical, Deep Learning, and Generative AI categories |\n",
    "| **4 API Functions** | `list()`, `steps()`, `show()`, `jupyter()` |\n",
    "| **Interactive Visualizations** | Browser-based with `show()`, notebook-embedded with `jupyter()` |\n",
    "| **Programmatic Access** | Full step-by-step data via `steps()` |\n",
    "| **Custom Inputs** | Override defaults for any algorithm |\n",
    "| **Deterministic** | Same inputs always produce identical output |\n",
    "| **Runs Locally** | Zero network access — everything runs on localhost |\n",
    "| **Type-Safe** | Full Python type hints with strict mypy checking |\n",
    "| **Minimal Dependencies** | Only Flask required at runtime |\n",
    "\n",
    "For more information, visit the [Eigenvue homepage](https://eigenvue.web.app/) or the [GitHub repository](https://github.com/eigenvue/eigenvue)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
