{
  "id": "convolution",
  "name": "Convolution (2D)",
  "category": "deep-learning",
  "description": {
    "short": "How CNNs detect features: sliding a kernel across an input grid.",
    "long": "Convolution is the core operation in Convolutional Neural Networks (CNNs). A small matrix called a kernel (or filter) slides across a 2D input (such as an image), computing the element-wise product between the kernel and each overlapping patch of the input, then summing the products to produce a single output value. This process generates an output feature map that highlights where certain features (edges, textures, patterns) appear in the input. The key insight of convolution is weight sharing — the same kernel weights are reused across all spatial positions, dramatically reducing the number of parameters compared to a fully connected layer. Convolution was popularized by LeCun et al. (1989) for handwritten digit recognition and remains the backbone of modern computer vision."
  },
  "complexity": {
    "time": "O(H × W × K² × C)",
    "space": "O(H × W + K²)",
    "level": "intermediate"
  },
  "visual": {
    "layout": "convolution-grid",
    "theme": {
      "primary": "#f59e0b",
      "secondary": "#d97706"
    },
    "components": {
      "showInput": true,
      "showKernel": true,
      "showOutput": true,
      "showProducts": true,
      "inputColor": "#38bdf8",
      "kernelColor": "#f59e0b",
      "outputColor": "#22c55e",
      "highlightColor": "#ef4444"
    }
  },
  "inputs": {
    "schema": {
      "input": {
        "type": "array",
        "items": {
          "type": "array",
          "items": {
            "type": "number",
            "minimum": -10,
            "maximum": 10
          }
        },
        "description": "2D input matrix (e.g., a grayscale image patch)."
      },
      "kernel": {
        "type": "array",
        "items": {
          "type": "array",
          "items": {
            "type": "number",
            "minimum": -5,
            "maximum": 5
          }
        },
        "description": "2D convolution kernel (filter)."
      }
    },
    "defaults": {
      "input": [
        [
          1,
          2,
          3,
          0
        ],
        [
          4,
          5,
          6,
          1
        ],
        [
          7,
          8,
          9,
          2
        ],
        [
          0,
          1,
          2,
          3
        ]
      ],
      "kernel": [
        [
          1,
          0
        ],
        [
          0,
          -1
        ]
      ]
    },
    "examples": [
      {
        "name": "Default (4×4 input, 2×2 kernel)",
        "values": {
          "input": [
            [
              1,
              2,
              3,
              0
            ],
            [
              4,
              5,
              6,
              1
            ],
            [
              7,
              8,
              9,
              2
            ],
            [
              0,
              1,
              2,
              3
            ]
          ],
          "kernel": [
            [
              1,
              0
            ],
            [
              0,
              -1
            ]
          ]
        }
      },
      {
        "name": "Edge detection (3×3 kernel)",
        "values": {
          "input": [
            [
              0,
              0,
              0,
              0,
              0
            ],
            [
              0,
              1,
              1,
              1,
              0
            ],
            [
              0,
              1,
              1,
              1,
              0
            ],
            [
              0,
              1,
              1,
              1,
              0
            ],
            [
              0,
              0,
              0,
              0,
              0
            ]
          ],
          "kernel": [
            [
              -1,
              -1,
              -1
            ],
            [
              -1,
              8,
              -1
            ],
            [
              -1,
              -1,
              -1
            ]
          ]
        }
      }
    ]
  },
  "code": {
    "implementations": {
      "pseudocode": "function convolve2D(input, kernel):\n  H, W = dimensions(input)\n  kH, kW = dimensions(kernel)\n  outH = H - kH + 1\n  outW = W - kW + 1\n  output = zeros(outH, outW)\n\n  for row in range(outH):\n    for col in range(outW):\n      sum = 0\n      for kr in range(kH):\n        for kc in range(kW):\n          sum += input[row+kr][col+kc] * kernel[kr][kc]\n      output[row][col] = sum\n  return output"
    },
    "defaultLanguage": "pseudocode"
  },
  "education": {
    "keyConcepts": [
      {
        "title": "Kernel Sliding",
        "description": "The kernel slides across the input one position at a time (stride=1). At each position, it computes the dot product between the kernel and the overlapping input patch. This produces one value in the output feature map."
      },
      {
        "title": "Weight Sharing",
        "description": "The same kernel weights are applied at every position in the input. This means the network detects the same feature regardless of where it appears — a property called translation equivariance."
      },
      {
        "title": "Feature Maps",
        "description": "Each kernel produces one feature map. Using multiple kernels (channels) allows the network to detect different features (edges, textures, shapes) simultaneously."
      }
    ],
    "pitfalls": [
      {
        "title": "Output size reduction",
        "description": "Without padding, convolution reduces spatial dimensions: output_size = input_size - kernel_size + 1. Use padding='same' to maintain dimensions."
      },
      {
        "title": "Kernel size must be ≤ input size",
        "description": "The kernel cannot be larger than the input in any dimension. This is a hard constraint of the convolution operation."
      }
    ],
    "quiz": [
      {
        "question": "What is the output size of convolving a 5×5 input with a 3×3 kernel (no padding, stride 1)?",
        "options": [
          "5×5",
          "4×4",
          "3×3",
          "2×2"
        ],
        "correctIndex": 2,
        "explanation": "Output size = input_size - kernel_size + 1 = 5 - 3 + 1 = 3. So the output is 3×3."
      }
    ],
    "resources": [
      {
        "title": "Backpropagation Applied to Handwritten Zip Code Recognition (LeCun et al., 1989)",
        "url": "https://ieeexplore.ieee.org/document/6795724",
        "type": "paper"
      },
      {
        "title": "Convolution — Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Convolutional_neural_network",
        "type": "article"
      }
    ]
  },
  "seo": {
    "keywords": [
      "convolution visualization",
      "CNN convolution step by step",
      "kernel sliding animation",
      "convolutional neural network explained",
      "2D convolution interactive"
    ],
    "ogDescription": "Interactive step-by-step visualization of 2D convolution. Watch the kernel slide across the input, compute element-wise products, and build the output feature map."
  },
  "prerequisites": [
    "perceptron"
  ],
  "related": [
    "feedforward-network",
    "backpropagation"
  ],
  "author": "eigenvue",
  "version": "1.0.0"
}
